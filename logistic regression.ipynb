{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': '100%', 'height': 768, 'scroll': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': \"100%\",\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# მანქანური სწავლება\n",
    "## SANGU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td><img src=\"csplus.png\" align=\"left\" style=\"height:100px\"></td>\n",
    "        <td><img src=\"sangu.png\" align=\"left\" style=\"height:100px\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ასოცირებული პროფესორი პაატა გოგიშვილი"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ლოგისტიკური რეგრესია"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ზოგადი თეორია\n",
    "\n",
    "მოცემულია მონაცემთა (წყვილების) სიმრავლე $X=(X^1, X^2, \\cdots, X^N)$ და $Y=(Y^1, Y^2, \\cdots, Y^N)$. უნდა ავაგოთ ნეირონული ქსელი რომელიც შეძლებს არსებული მონაცემების სწორ კლასიფიკაციას.\n",
    "\n",
    "წრფივი რეგრესიისგან განსხვავებით, უნდა ავიღოთ იმდენი ნეირონი, რამდენი კლასიც გვაქვს. თითოეული ნეირონი უნდა იყოს განპირობებული შესაბამის კლასზე.\n",
    "\n",
    "თითოეული ნეირონი უნდა იძლეოდეს მისთვის შესაბამებული კლასის არსებობის ალბათობას.\n",
    "\n",
    "ამ მიზნის მისაღწევად, თითოეული ნეირონის მოქმედების ფუნქცია უნდა იყოს შემდეგი ხასიათის: \n",
    "\n",
    "$$f=\\sigma{\\left(\\sum_{i=1}^n x_i w_i + b\\right)}$$\n",
    "\n",
    "სადაც $\\sigma$ ლოგისტიკურ ფუნქციას წარმოადგენს $\\sigma(z)=\\frac{1}{1+e^{-z}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ზამბახების მონაცემების მომზადება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1 2 0 0 2 1 0 0\n",
      " 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0]\n",
      "(100, 4), (100,)\n",
      "[0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2\n",
      " 2 0 1 1 1 1 0 0 0 2 1 2 0]\n",
      "(50, 4), (50,)\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils as ut \n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "X, y = ut.shuffle(X, y, random_state=0)\n",
    "\n",
    "\n",
    "n_test = 50\n",
    "\n",
    "\n",
    "X_test = X[150 - n_test : ]\n",
    "y_test = y[150 - n_test : ]\n",
    "\n",
    "X = X[:150 - n_test]\n",
    "y = y[:150 - n_test]\n",
    "\n",
    "\n",
    "print(f'{y}')\n",
    "print(f'{X.shape}, {y.shape}')\n",
    "\n",
    "print(f'{y_test}')\n",
    "print(f'{X_test.shape}, {y_test.shape}')\n",
    "\n",
    "print(f'{iris.feature_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b$ პარამეტრი ჯამის ნიშანში შევიტანოთ.\n",
    "გამოთვლების სწორად ჩასატარებლად $X$ მასივს უნდა მივამატოთ კიდევ ერთი სვეტი.\n",
    "\n",
    "$$z=\\sum_{i=1}^n x_i w_i + b$$\n",
    "\n",
    "$x_{n+1}=1$, $w_{n+1}=b$, \n",
    "\n",
    "$$z=\\sum_{i=1}^{n+1} x_i w_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X, np.ones(len(X))]\n",
    "X_test = np.c_[X_test, np.ones(len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.linalg as la\n",
    "import scipy.optimize as opt\n",
    "\n",
    "WW = np.array([0.1, 0.1, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1 2 0 0 2 1 0 0\n",
      " 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0] 1\n",
      "LabelEncoder() 2\n",
      "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
      "       handle_unknown='error', n_values='auto', sparse=False) 3\n",
      "[[2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]] 4\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]] 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "values = np.copy(y)\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "print(f'{y}', 1)\n",
    "print(f'{label_encoder}', 2)\n",
    "print(f'{onehot_encoder}', 3)\n",
    "print(f'{integer_encoded}', 4)\n",
    "print(f'{onehot_encoded}', 5)\n",
    "\n",
    "\n",
    "values_test = np.copy(y_test)\n",
    "\n",
    "# integer encode\n",
    "label_encoder_test = LabelEncoder()\n",
    "integer_encoded_test = label_encoder_test.fit_transform(values_test)\n",
    "# binary encode\n",
    "onehot_encoder_test = OneHotEncoder(sparse=False)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "onehot_encoded_test = onehot_encoder_test.fit_transform(integer_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 ********************************** \n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000004\n",
      "         Iterations: 17\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 56\n",
      "x [[  3.01480603   7.8961513  -13.96815064  -7.47464482   1.84131374]\n",
      " [  0.           0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.        ]]\n",
      "\n",
      "1 ********************************** \n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 51.192458\n",
      "         Iterations: 151\n",
      "         Function evaluations: 332\n",
      "         Gradient evaluations: 332\n",
      "x [[  3.01480603   7.8961513  -13.96815064  -7.47464482   1.84131374]\n",
      " [ -0.08247043  -2.24820712   1.34312704  -2.90556124   4.81294521]\n",
      " [  0.           0.           0.           0.           0.        ]]\n",
      "\n",
      "2 ********************************** \n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.943689\n",
      "         Iterations: 129\n",
      "         Function evaluations: 332\n",
      "         Gradient evaluations: 329\n",
      "x [[  3.01480603   7.8961513  -13.96815064  -7.47464482   1.84131374]\n",
      " [ -0.08247043  -2.24820712   1.34312704  -2.90556124   4.81294521]\n",
      " [ -1.44474989  -4.05081737   7.46854613  16.035693   -41.96579713]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def f(w):\n",
    "    return ff(w, X, y)\n",
    "    \n",
    "def ff(w, x, y):\n",
    "    return -np.sum(y * np.log(sigmoid(np.matmul(x, w))) + (1 - y) * np.log(sigmoid(-np.matmul(x, w))))\n",
    "    \n",
    "def f_prime(z):\n",
    "    p = (sigmoid(np.matmul(X, z)) - y)\n",
    "    return np.matmul(np.transpose(X), p)\n",
    "\n",
    "def ca(WW):\n",
    "    pass\n",
    "\n",
    "x = np.zeros((3, 5))\n",
    "    \n",
    "for i in range(3):\n",
    "    print()\n",
    "    print(f\"{i} ********************************** \")\n",
    "    print()\n",
    "    y = onehot_encoded[:,i]\n",
    "    x[i] = opt.fmin_cg(f, WW, fprime=f_prime, callback=ca)\n",
    "    print('x',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    \"\"\"წრფივი რეგრესია\"\"\"\n",
    "    \n",
    "    def __init__(self, W:np.ndarray, b:float):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.dl_W = None\n",
    "        self.dl_b = None\n",
    "        \n",
    "    def forward(self, X:np.ndarray) -> np.ndarray:\n",
    "        return X @ self.W.T + self.b\n",
    "    \n",
    "    def loss(self, X:np.ndarray, y:np.ndarray) -> np.ndarray:\n",
    "        y_pred = self.forward(X)\n",
    "        lss = y_pred - y\n",
    "        \n",
    "        return lss\n",
    "    \n",
    "    def cost(self, X:np.ndarray, y:np.ndarray) -> float:\n",
    "        lss = self.loss(X, y)\n",
    "        cs = (1.0 / (2.0 * len(X))) * np.sum(lss**2)\n",
    "        \n",
    "        return cs\n",
    "    \n",
    "    def gradient(self, X:np.ndarray, y:np.ndarray):\n",
    "        lss = self.loss(X, y)\n",
    "        coef = 1.0 / len(X)\n",
    "        self.dl_W = coef * np.sum(X * lss, axis=0)\n",
    "        self.dl_b = coef + np.sum(lss, axis=0)\n",
    "        \n",
    "        return self.dl_W, self.dl_b\n",
    "    \n",
    "    @property\n",
    "    def grad_w(self) -> np.ndarray:\n",
    "        return self.dl_W\n",
    "    \n",
    "    @property\n",
    "    def grad_b(self) -> np.ndarray:\n",
    "        return self.dl_b\n",
    "    \n",
    "    def update(self, lr:float):\n",
    "        self.W = self.W - (lr * self.dl_W)\n",
    "        self.b = self.b - (lr * self.dl_b)\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \"\"\"წრფივი რეგრესიის მწვრთნელი\"\"\"\n",
    "    \n",
    "    def __init__(self, model: callable, lr:float=0.001, n_iters:int=10, t_iter:int=10):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.t_iter = t_iter\n",
    "        \n",
    "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
    "        cs = list()\n",
    "        for i in range(self.n_iters):\n",
    "            c = self.model.cost(X, y)\n",
    "            cs.append(c)\n",
    "            d_W, d_b = self.model.gradient(X, y)\n",
    "            self.model.update(self.lr)\n",
    "            if i % self.t_iter == 0:\n",
    "                print(f'Gradients {self.model.dl_W}, {self.model.dl_b}')\n",
    "                print(f'Weights {self.model.W}, {self.model.b}')\n",
    "                print(f'Iteration {i} cost = {c}')\n",
    "        self.y_preds = self.model(X)\n",
    "        \n",
    "        return self.y_preds\n",
    "    \n",
    "    def validate(self, X:np.ndarray, y:np.ndarray) -> float:\n",
    "        y_pred = np.rint(self.model(X))\n",
    "        score = float(sum(y_pred == y)) / float(len(y))\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 ********************************** \n",
      "\n",
      "Gradients [-2.324 -1.054 -1.951 -0.716 -0.36 ], [-35.99]\n",
      "Weights [[2.324e-04 1.054e-04 1.951e-04 7.160e-05 3.600e-05]], [0.003599]\n",
      "Iteration 0 cost = 0.18\n",
      "Gradients [ 0.00287884 -0.01737736 -0.01557664 -0.03109214  0.00125568], [0.13556844]\n",
      "Weights [[ 0.03456994 -0.00726508  0.14345558  0.08761441 -0.00458721]], [-0.46872227]\n",
      "Iteration 10000 cost = 0.054884482473099856\n",
      "Gradients [ 0.00674956 -0.01997065  0.00300387 -0.02142824  0.00026248], [0.03624813]\n",
      "Weights [[ 0.02890135  0.01257815  0.14547065  0.11196579 -0.00514117]], [-0.53411805]\n",
      "Iteration 20000 cost = 0.053784401456295906\n",
      "Gradients [ 0.006932   -0.01784665  0.00358131 -0.01987463  0.00014605], [0.0246055]\n",
      "Weights [[ 0.02201411  0.03151169  0.14199577  0.13252789 -0.00533525]], [-0.56352642]\n",
      "Iteration 30000 cost = 0.052937147411744184\n",
      "Gradients [ 6.85573957e-03 -1.58045544e-02  3.41320331e-03 -1.87464172e-02\n",
      "  8.15337622e-05], [0.01815338]\n",
      "Weights [[ 0.01511108  0.04831619  0.1384934   0.15182863 -0.00544756]], [-0.58475718]\n",
      "Iteration 40000 cost = 0.05221942265702165\n",
      "Gradients [ 6.69351859e-03 -1.40116490e-02  3.24320140e-03 -1.77045367e-02\n",
      "  3.06385856e-05], [0.01306386]\n",
      "Weights [[ 0.0083307   0.06320436  0.13516728  0.17004817 -0.00550272]], [-0.60027325]\n",
      "Iteration 50000 cost = 0.051607525615528574\n",
      "Gradients [ 6.47200454e-03 -1.24402381e-02  3.09804335e-03 -1.67296713e-02\n",
      " -1.02949990e-05], [0.0089705]\n",
      "Weights [[ 0.00174376  0.07641312  0.13199863  0.18725988 -0.00551215]], [-0.61121552]\n",
      "Iteration 60000 cost = 0.05108296939396114\n",
      "Gradients [ 6.20782854e-03 -1.10595571e-02  2.97428278e-03 -1.58167195e-02\n",
      " -4.30849437e-05], [0.00569151]\n",
      "Weights [[-0.0045991   0.08814822  0.12896408  0.20352805 -0.00548484]], [-0.61848498]\n",
      "Iteration 70000 cost = 0.050631111435099754\n",
      "Gradients [ 5.91415319e-03 -9.84324006e-03  2.86797704e-03 -1.49614875e-02\n",
      " -6.91851565e-05], [0.00308148]\n",
      "Weights [[-0.01066206  0.09858685  0.12604426  0.21891247 -0.0054282 ]], [-0.62282095]\n",
      "Iteration 80000 cost = 0.05024022151275119\n",
      "Gradients [ 5.60149662e-03 -8.76891648e-03  2.77583825e-03 -1.41600919e-02\n",
      " -8.97978552e-05], [0.00102021]\n",
      "Weights [[-0.01642107  0.10788188  0.12322342  0.23346889 -0.00534829]], [-0.62483041]\n",
      "Iteration 90000 cost = 0.04990079976848\n",
      "Gradients [ 0.00527821 -0.00781758  0.00269517 -0.01340892 -0.00010592], [-0.00059183]\n",
      "Weights [[-0.0218615   0.11616554  0.12048878  0.24724931 -0.0052501 ]], [-0.62501075]\n",
      "Iteration 100000 cost = 0.049605075205644694\n",
      "Gradients [ 0.00495089 -0.00697307  0.00262375 -0.01270459 -0.00011837], [-0.00183699]\n",
      "Weights [[-0.02697614  0.12355254  0.11783001  0.26030226 -0.00513768]], [-0.62376874]\n",
      "Iteration 110000 cost = 0.049346633311459484\n",
      "Gradients [ 0.00462466 -0.0062216   0.00255979 -0.01204397 -0.00012783], [-0.00278334]\n",
      "Weights [[-0.03176363  0.1301426   0.1152388   0.27267298 -0.00501435]], [-0.62143613]\n",
      "Iteration 120000 cost = 0.04912013656785346\n",
      "Gradients [ 0.00430348 -0.00555139  0.0025018  -0.01142413 -0.00013487], [-0.00348709]\n",
      "Weights [[-0.03622712  0.13602274  0.11270845  0.28440372 -0.00488282]], [-0.61828273]\n",
      "Iteration 130000 cost = 0.04892111226061615\n",
      "Gradients [ 0.00399034 -0.00495234  0.0024486  -0.01084236 -0.00013995], [-0.00399463]\n",
      "Weights [[-0.04037324  0.14126902  0.11023361  0.29553387 -0.00474526]], [-0.61452719]\n",
      "Iteration 140000 cost = 0.04874578944810112\n",
      "Gradients [ 0.00368745 -0.00441582  0.0023992  -0.0102961  -0.00014344], [-0.00434418]\n",
      "Weights [[-0.04421119  0.14594819  0.10780999  0.30610021 -0.00460345]], [-0.61034601]\n",
      "Iteration 150000 cost = 0.0485909721722213\n",
      "Gradients [ 0.00339639 -0.00393437  0.00235284 -0.009783   -0.00014567], [-0.00456718]\n",
      "Weights [[-0.04775205  0.15011896  0.1054342   0.31613707 -0.0044588 ]], [-0.60588093]\n",
      "Iteration 160000 cost = 0.048453939661647794\n",
      "Gradients [ 0.00311825 -0.00350158  0.00230887 -0.00930086 -0.00014689], [-0.00468948]\n",
      "Weights [[-0.05100825  0.15383311  0.10310352  0.32567649 -0.00431244]], [-0.60124515]\n",
      "Iteration 170000 cost = 0.048332366860066804\n",
      "Gradients [ 0.0028537  -0.00311188  0.00226679 -0.00884763 -0.00014732], [-0.00473226]\n",
      "Weights [[-0.05399306  0.15713644  0.10081584  0.33474839 -0.00416527]], [-0.59652843]\n",
      "Iteration 180000 cost = 0.04822426043793263\n",
      "Gradients [ 0.00260309 -0.00276047  0.00222621 -0.00842139 -0.00014713], [-0.00471289]\n",
      "Weights [[-0.05672027  0.16006959  0.09856945  0.3433807  -0.004018  ]], [-0.59180131]\n",
      "Iteration 190000 cost = 0.04812790674182007\n",
      "Gradients [ 0.00236652 -0.00244316  0.00218681 -0.00802037 -0.00014646], [-0.00464552]\n",
      "Weights [[-0.05920389  0.16266871  0.09636302  0.35159953 -0.00387118]], [-0.58711863]\n",
      "Iteration 200000 cost = 0.04804182905960563\n",
      "Gradients [ 0.00214391 -0.0021563   0.00214834 -0.00764291 -0.00014542], [-0.00454167]\n",
      "Weights [[-0.06145795  0.16496603  0.09419552  0.35942925 -0.00372521]], [-0.58252242]\n",
      "Iteration 210000 cost = 0.04796475224268391\n",
      "Gradients [ 0.00193501 -0.00189669  0.0021106  -0.00728746 -0.00014411], [-0.00441072]\n",
      "Weights [[-0.06349627  0.16699036  0.09206611  0.36689264 -0.00358043]], [-0.57804431]\n",
      "Iteration 220000 cost = 0.04789557320528972\n",
      "Gradients [ 0.00173946 -0.00166153  0.00207346 -0.00695258 -0.0001426 ], [-0.00426023]\n",
      "Weights [[-0.0653324   0.16876752  0.08997412  0.37401099 -0.00343706]], [-0.57370748]\n",
      "Iteration 230000 cost = 0.04783333616957963\n",
      "Gradients [ 0.00155682 -0.00144837  0.0020368  -0.00663695 -0.00014096], [-0.00409629]\n",
      "Weights [[-0.06697948  0.17032073  0.08791903  0.38080419 -0.00329527]], [-0.56952833]\n",
      "Iteration 240000 cost = 0.04777721178112123\n",
      "Gradients [ 0.00138659 -0.00125503  0.00200054 -0.0063393  -0.00013924], [-0.00392377]\n",
      "Weights [[-0.06845016  0.17167085  0.08590039  0.38729085 -0.00315517]], [-0.56551777]\n",
      "Iteration 250000 cost = 0.04772647940928433\n",
      "Gradients [ 0.00122822 -0.00107959  0.00196463 -0.00605848 -0.00013747], [-0.00374655]\n",
      "Weights [[-0.06975659  0.17283674  0.08391784  0.39348837 -0.00301681]], [-0.56168237]\n",
      "Iteration 260000 cost = 0.04768051208932835\n",
      "Gradients [ 0.00108117 -0.00092033  0.00192902 -0.0057934  -0.00013568], [-0.00356769]\n",
      "Weights [[-0.07091036  0.17383541  0.08197104  0.39941303 -0.00288024]], [-0.55802523]\n",
      "Iteration 270000 cost = 0.04763876367086346\n",
      "Gradients [ 0.00094484 -0.00077575  0.00189369 -0.00554305 -0.0001339 ], [-0.00338959]\n",
      "Weights [[-0.07192248  0.17468228  0.08005971  0.40508005 -0.00274546]], [-0.55454675]\n",
      "Iteration 280000 cost = 0.04760075782012761\n",
      "Gradients [ 0.00081866 -0.00064449  0.00185863 -0.00530649 -0.00013214], [-0.00321407]\n",
      "Weights [[-0.07280341  0.17539134  0.07818357  0.4105037  -0.00261244]], [-0.55124521]\n",
      "Iteration 290000 cost = 0.04756607858779015\n",
      "x [[0.11623617 0.11623617 0.11623617 0.11623617 0.11623617]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "\n",
      "1 ********************************** \n",
      "\n",
      "Gradients [ 0.00070207 -0.00052533  0.00182384 -0.00508284 -0.00013043], [-0.00304255]\n",
      "Weights [[-0.07356299  0.17597528  0.07634236  0.41569731 -0.00248116]], [-0.54811728]\n",
      "Iteration 0 cost = 0.047534362304499436\n",
      "Gradients [ 0.00059448 -0.00041719  0.00178931 -0.00487128 -0.00012876], [-0.00287606]\n",
      "Weights [[-0.07421053  0.17644566  0.07453581  0.42067338 -0.00235157]], [-0.54515844]\n",
      "Iteration 10000 cost = 0.047505290606550885\n",
      "Gradients [ 0.00049537 -0.0003191   0.00175505 -0.00467106 -0.00012715], [-0.00271535]\n",
      "Weights [[-0.07475477  0.17681301  0.07276366  0.42544363 -0.00222362]], [-0.54236325]\n",
      "Iteration 20000 cost = 0.047478584426338614\n",
      "Gradients [ 0.0004042  -0.00023016  0.00172108 -0.00448145 -0.00012561], [-0.00256092]\n",
      "Weights [[-0.07520391  0.1770869   0.07102562  0.43001901 -0.00209725]], [-0.53972567]\n",
      "Iteration 30000 cost = 0.04745399880847645\n",
      "Gradients [ 0.00032045 -0.0001496   0.00168741 -0.0043018  -0.00012413], [-0.0024131]\n",
      "Weights [[-0.07556563  0.17727611  0.0693214   0.43440983 -0.00197238]], [-0.53723922]\n",
      "Iteration 40000 cost = 0.04743131843397589\n",
      "Gradients [ 2.43654243e-04 -7.66731020e-05  1.65404473e-03 -4.13149148e-03\n",
      " -1.22720642e-04], [-0.00227206]\n",
      "Weights [[-0.07584712  0.17738863  0.0676507   0.43862571 -0.00184896]], [-0.53489722]\n",
      "Iteration 50000 cost = 0.047410353752642215\n",
      "Gradients [ 1.73338099e-04 -1.07442497e-05  1.62100905e-03 -3.96994120e-03\n",
      " -1.21378708e-04], [-0.00213787]\n",
      "Weights [[-0.07605509  0.17743178  0.06601321  0.44267571 -0.00172692]], [-0.53269283]\n",
      "Iteration 60000 cost = 0.04739093763865279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients [ 1.09063915e-04  4.87841983e-05  1.58831560e-03 -3.81661332e-03\n",
      " -1.20104836e-04], [-0.00201048]\n",
      "Weights [[-0.07619581  0.17741225  0.06440857  0.44656832 -0.00160618]], [-0.53061922]\n",
      "Iteration 70000 cost = 0.04737292249668662\n",
      "Gradients [ 5.04151372e-05  1.02451868e-04  1.55597962e-03 -3.67100547e-03\n",
      " -1.18897972e-04], [-0.0018898]\n",
      "Weights [[-0.07627509  0.17733616  0.06283646  0.4503115  -0.00148669]], [-0.52866964]\n",
      "Iteration 80000 cost = 0.047356177756427136\n",
      "Gradients [-3.00166555e-06  1.50750575e-04  1.52401588e-03 -3.53264881e-03\n",
      " -1.17756525e-04], [-0.00177565]\n",
      "Weights [[-0.07629837  0.17720913  0.06129649  0.45391273 -0.00136836]], [-0.52683746]\n",
      "Iteration 90000 cost = 0.04734058770210748\n",
      "Gradients [-5.15572786e-05  1.94129210e-04  1.49243836e-03 -3.40110569e-03\n",
      " -1.16678510e-04], [-0.00166785]\n",
      "Weights [[-0.0762707   0.17703629  0.0597883   0.45737905 -0.00125115]], [-0.52511623]\n",
      "Iteration 100000 cost = 0.04732604959128549\n",
      "Gradients [-9.56004719e-05  2.32998016e-04  1.46126017e-03 -3.27596754e-03\n",
      " -1.15661658e-04], [-0.00156617]\n",
      "Weights [[-0.07619676  0.17682237  0.05831149  0.46071707 -0.00113499]], [-0.52349973]\n",
      "Iteration 110000 cost = 0.047312472023443276\n",
      "Gradients [-0.00013546  0.00026773  0.00143049 -0.00315685 -0.0001147 ], [-0.00147035]\n",
      "Weights [[-0.07608089  0.17657167  0.05686565  0.46393298 -0.00101981]], [-0.52198195]\n",
      "Iteration 120000 cost = 0.047299773524483175\n",
      "Gradients [-0.00017144  0.00029868  0.00140015 -0.00304341 -0.0001138 ], [-0.00138015]\n",
      "Weights [[-0.07592713  0.17628816  0.05545036  0.46703265 -0.00090556]], [-0.52055716]\n",
      "Iteration 130000 cost = 0.047287881317881246\n",
      "Gradients [-0.00020383  0.00032614  0.00137024 -0.00293529 -0.00011295], [-0.00129529]\n",
      "Weights [[-0.07573921  0.17597548  0.05406521  0.47002156 -0.00079219]], [-0.51921988]\n",
      "Iteration 140000 cost = 0.04727673025728506\n",
      "Gradients [-0.0002329   0.00035043  0.00134077 -0.0028322  -0.00011216], [-0.00121552]\n",
      "Weights [[-0.07552058  0.17563693  0.05270974  0.4729049  -0.00067964]], [-0.51796489]\n",
      "Iteration 150000 cost = 0.047266261898798546\n",
      "Gradients [-0.0002589   0.00037179  0.00131174 -0.00273384 -0.00011141], [-0.00114056]\n",
      "Weights [[-0.07527443  0.17527559  0.05138353  0.47568753 -0.00056786]], [-0.51678725]\n",
      "Iteration 160000 cost = 0.04725642369417267\n",
      "Gradients [-0.00028206  0.00039048  0.00128317 -0.00263995 -0.0001107 ], [-0.00107016]\n",
      "Weights [[-7.50037240e-02  1.74894246e-01  5.00861108e-02  4.78374060e-01\n",
      "  -4.56812643e-04]], [-0.51568226]\n",
      "Iteration 170000 cost = 0.04724716828868017\n",
      "Gradients [-0.00030261  0.00040671  0.00125507 -0.00255026 -0.00011004], [-0.00100406]\n",
      "Weights [[-7.47111804e-02  1.74495457e-01  4.88170300e-02  4.80968816e-01\n",
      "  -3.46445079e-04]], [-0.51464551]\n",
      "Iteration 180000 cost = 0.047238452909661124\n",
      "Gradients [-0.00032074  0.0004207   0.00122742 -0.00246453 -0.00010942], [-0.00094201]\n",
      "Weights [[-7.43993137e-02  1.74081572e-01  4.75758250e-02  4.83475884e-01\n",
      "  -2.36718026e-04]], [-0.5136728]\n",
      "Iteration 190000 cost = 0.04723023883362764\n",
      "Gradients [-0.00033665  0.00043264  0.00120025 -0.00238256 -0.00010884], [-0.00088379]\n",
      "Weights [[-7.40704408e-02  1.73654740e-01  4.63620295e-02  4.85899122e-01\n",
      "  -1.27592111e-04]], [-0.51276021]\n",
      "Iteration 200000 cost = 0.0472224909214584\n",
      "Gradients [-0.00035051  0.00044269  0.00117354 -0.00230412 -0.00010829], [-0.00082916]\n",
      "Weights [[-7.37266959e-02  1.73216926e-01  4.51751746e-02  4.88242171e-01\n",
      "  -1.90302818e-05]], [-0.51190403]\n",
      "Iteration 210000 cost = 0.04721517721263076\n",
      "Gradients [-0.00036249  0.00045103  0.00114731 -0.00222903 -0.00010778], [-0.0007779]\n",
      "Weights [[-7.33700426e-02  1.72769928e-01  4.40147893e-02  4.90508470e-01\n",
      "   8.90022930e-05]], [-0.51110077]\n",
      "Iteration 220000 cost = 0.04720826857066112\n",
      "Gradients [-0.00037274  0.0004578   0.00112155 -0.0021571  -0.0001073 ], [-0.00072982]\n",
      "Weights [[-7.30022864e-02  1.72315387e-01  4.28804015e-02  4.92701272e-01\n",
      "   1.96538327e-04]], [-0.51034717]\n",
      "Iteration 230000 cost = 0.04720173837298112\n",
      "Gradients [-0.0003814   0.00046314  0.00109626 -0.00208815 -0.00010685], [-0.0006847]\n",
      "Weights [[-7.26250855e-02  1.71854805e-01  4.17715390e-02  4.94823650e-01\n",
      "   3.03608523e-04]], [-0.50964015]\n",
      "Iteration 240000 cost = 0.04719556223938959\n",
      "Gradients [-0.00038861  0.00046717  0.00107144 -0.00202204 -0.00010642], [-0.00064238]\n",
      "Weights [[-7.22399617e-02  1.71389548e-01  4.06877302e-02  4.96878516e-01\n",
      "   4.10241672e-04]], [-0.50897683]\n",
      "Iteration 250000 cost = 0.04718971779400935\n",
      "Gradients [-0.00039448  0.00047001  0.00104709 -0.00195861 -0.00010603], [-0.00060266]\n",
      "Weights [[-0.07184831  0.17092086  0.0396285   0.49886862  0.00051646]], [-0.50835452]\n",
      "Iteration 260000 cost = 0.047184184456358795\n",
      "Gradients [-0.00039913  0.00047177  0.00102321 -0.00189772 -0.00010565], [-0.0005654]\n",
      "Weights [[-0.07145141  0.17044989  0.03859339  0.50079658  0.0006223 ]], [-0.50777069]\n",
      "Iteration 270000 cost = 0.04717894325773807\n",
      "Gradients [-0.00040266  0.00047255  0.0009998  -0.00183924 -0.0001053 ], [-0.00053042]\n",
      "Weights [[-0.07105042  0.16997765  0.03758193  0.50266486  0.00072778]], [-0.50722297]\n",
      "Iteration 280000 cost = 0.04717397667963781\n",
      "Gradients [-0.00040517  0.00047244  0.00097684 -0.00178304 -0.00010498], [-0.00049759]\n",
      "Weights [[-0.07064642  0.16950509  0.03659365  0.50447581  0.00083292]], [-0.50670914]\n",
      "Iteration 290000 cost = 0.04716926851132029\n",
      "x [[0.11623617 0.11623617 0.11623617 0.11623617 0.11623617]\n",
      " [0.09388506 0.09388506 0.09388506 0.09388506 0.09388506]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "\n",
      "2 ********************************** \n",
      "\n",
      "Gradients [-0.00040676  0.00047151  0.00095435 -0.00172901 -0.00010467], [-0.00046676]\n",
      "Weights [[-0.07024038  0.16903305  0.0356281   0.50623165  0.00093774]], [-0.50622713]\n",
      "Iteration 0 cost = 0.047164803724101534\n",
      "Gradients [-0.0004075   0.00046986  0.0009323  -0.00167703 -0.00010438], [-0.00043781]\n",
      "Weights [[-0.06983319  0.1685623   0.03468481  0.5079345   0.00104226]], [-0.50577501]\n",
      "Iteration 10000 cost = 0.04716056836019432\n",
      "Gradients [-0.00040747  0.00046755  0.00091071 -0.00162702 -0.00010411], [-0.00041061]\n",
      "Weights [[-0.06942564  0.16809354  0.03376334  0.50958637  0.0011465 ]], [-0.50535094]\n",
      "Iteration 20000 cost = 0.04715654943425514\n",
      "Gradients [-0.00040674  0.00046465  0.00088956 -0.00157886 -0.00010385], [-0.00038506]\n",
      "Weights [[-0.06901849  0.16762739  0.03286324  0.51118916  0.00125048]], [-0.50495324]\n",
      "Iteration 30000 cost = 0.047152734846025515\n",
      "Gradients [-0.00040538  0.00046122  0.00086885 -0.00153248 -0.00010361], [-0.00036104]\n",
      "Weights [[-0.06861238  0.16716442  0.03198407  0.51274468  0.00135421]], [-0.50458032]\n",
      "Iteration 40000 cost = 0.047149113302670805\n",
      "Gradients [-0.00040345  0.00045731  0.00084858 -0.00148778 -0.00010338], [-0.00033846]\n",
      "Weights [[-0.06820792  0.16670512  0.03112539  0.51425467  0.0014577 ]], [-0.50423069]\n",
      "Iteration 50000 cost = 0.04714567424960423\n",
      "Gradients [-0.00040101  0.00045297  0.00082873 -0.00144468 -0.00010317], [-0.00031722]\n",
      "Weights [[-0.06780565  0.16624994  0.03028677  0.51572077  0.00156098]], [-0.50390296]\n",
      "Iteration 60000 cost = 0.04714240780874369\n",
      "Gradients [-0.0003981   0.00044826  0.00080931 -0.00140311 -0.00010297], [-0.00029723]\n",
      "Weights [[-0.06740606  0.1657993   0.02946779  0.51714454  0.00166405]], [-0.50359584]\n",
      "Iteration 70000 cost = 0.047139304723286396\n",
      "Gradients [-0.00039478  0.00044321  0.00079031 -0.001363   -0.00010278], [-0.00027842]\n",
      "Weights [[-0.06700959  0.16535354  0.02866801  0.51852748  0.00176693]], [-0.50330811]\n",
      "Iteration 80000 cost = 0.0471363563082072\n",
      "Gradients [-0.00039109  0.00043787  0.00077171 -0.00132429 -0.00010261], [-0.00026071]\n",
      "Weights [[-0.06661663  0.16491297  0.02788704  0.51987101  0.00186962]], [-0.50303863]\n",
      "Iteration 90000 cost = 0.04713355440578879\n",
      "Gradients [-0.00038707  0.00043228  0.00075352 -0.0012869  -0.00010244], [-0.00024403]\n",
      "Weights [[-0.06622752  0.16447787  0.02712446  0.52117649  0.00197215]], [-0.50278635]\n",
      "Iteration 100000 cost = 0.04713089134558259\n",
      "Gradients [-0.00038276  0.00042646  0.00073573 -0.00125078 -0.00010228], [-0.0002283]\n",
      "Weights [[-0.06584258  0.16404849  0.02637987  0.52244522  0.00207451]], [-0.50255026]\n",
      "Iteration 110000 cost = 0.04712835990827652\n",
      "Gradients [-0.00037819  0.00042044  0.00071833 -0.00121587 -0.00010213], [-0.00021348]\n",
      "Weights [[-0.06546209  0.16362503  0.02565288  0.52367845  0.00217672]], [-0.50232945]\n",
      "Iteration 120000 cost = 0.04712595329301335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients [-0.0003734   0.00041427  0.00070131 -0.00118212 -0.00010199], [-0.00019949]\n",
      "Weights [[-0.06508628  0.16320766  0.02494309  0.52487735  0.00227878]], [-0.50212303]\n",
      "Iteration 130000 cost = 0.04712366508776148\n",
      "Gradients [-0.00036841  0.00040795  0.00068467 -0.00114949 -0.00010186], [-0.0001863]\n",
      "Weights [[-0.06471536  0.16279654  0.02425013  0.52604306  0.00238071]], [-0.5019302]\n",
      "Iteration 140000 cost = 0.047121489242390874\n",
      "Gradients [-0.00036325  0.00040152  0.0006684  -0.00111791 -0.00010174], [-0.00017384]\n",
      "Weights [[-0.06434952  0.1623918   0.02357363  0.52717667  0.00248251]], [-0.50175019]\n",
      "Iteration 150000 cost = 0.04711942004415108\n",
      "Gradients [-0.00035794  0.000395    0.0006525  -0.00108736 -0.00010162], [-0.00016207]\n",
      "Weights [[-0.06398891  0.16199353  0.02291321  0.52827922  0.00258419]], [-0.50158229]\n",
      "Iteration 160000 cost = 0.04711745209528521\n",
      "Gradients [-0.00035252  0.0003884   0.00063696 -0.00105777 -0.00010151], [-0.00015095]\n",
      "Weights [[-0.06363367  0.16160182  0.0222685   0.5293517   0.00268575]], [-0.50142583]\n",
      "Iteration 170000 cost = 0.04711558029254863\n",
      "Gradients [-0.00034699  0.00038176  0.00062177 -0.00102913 -0.0001014 ], [-0.00014043]\n",
      "Weights [[-0.06328391  0.16121674  0.02163917  0.53039508  0.00278721]], [-0.50128019]\n",
      "Iteration 180000 cost = 0.04711379980842824\n",
      "Gradients [-0.00034138  0.00037507  0.00060692 -0.00100138 -0.0001013 ], [-0.00013048]\n",
      "Weights [[-0.06293971  0.16083833  0.02102485  0.53141026  0.00288856]], [-0.50114478]\n",
      "Iteration 190000 cost = 0.04711210607388378\n",
      "Gradients [-0.00033571  0.00036836  0.00059242 -0.0009745  -0.00010121], [-0.00012106]\n",
      "Weights [[-0.06260116  0.16046661  0.02042521  0.53239812  0.00298982]], [-0.50101905]\n",
      "Iteration 200000 cost = 0.047110494762455\n",
      "Gradients [-0.00032998  0.00036164  0.00057824 -0.00094844 -0.00010112], [-0.00011214]\n",
      "Weights [[-0.06226831  0.16010161  0.01983991  0.53335952  0.00309099]], [-0.50090249]\n",
      "Iteration 210000 cost = 0.04710896177559575\n",
      "Gradients [-0.00032423  0.00035492  0.00056439 -0.00092318 -0.00010104], [-0.00010369]\n",
      "Weights [[-0.06194121  0.15974333  0.01926862  0.53429526  0.00319206]], [-0.50079461]\n",
      "Iteration 220000 cost = 0.0471075032291145\n",
      "Gradients [-0.00031845  0.00034822  0.00055086 -0.00089868 -0.00010096], [-9.56774012e-05]\n",
      "Weights [[-0.06161987  0.15939176  0.01871102  0.53520612  0.00329306]], [-0.50069496]\n",
      "Iteration 230000 cost = 0.047106115440613196\n",
      "Gradients [-0.00031266  0.00034155  0.00053764 -0.00087492 -0.00010088], [-8.80749267e-05]\n",
      "Weights [[-0.06130432  0.15904688  0.0181668   0.53609286  0.00339398]], [-0.50060312]\n",
      "Iteration 240000 cost = 0.047104794917830456\n",
      "Gradients [-0.00030687  0.0003349   0.00052473 -0.00085186 -0.00010081], [-8.08586949e-05]\n",
      "Weights [[-0.06099456  0.15870866  0.01763564  0.53695619  0.00349482]], [-0.50051868]\n",
      "Iteration 250000 cost = 0.0471035383478047\n",
      "Gradients [-0.00030109  0.0003283   0.00051212 -0.00082949 -0.00010074], [-7.40051731e-05]\n",
      "Weights [[-0.06069058  0.15837706  0.01711724  0.53779681  0.0035956 ]], [-0.50044128]\n",
      "Iteration 260000 cost = 0.04710234258678311\n",
      "Gradients [-0.00029533  0.00032175  0.0004998  -0.00080778 -0.00010067], [-6.74923895e-05]\n",
      "Weights [[-0.06039238  0.15805203  0.01661131  0.53861539  0.0036963 ]], [-0.50037056]\n",
      "Iteration 270000 cost = 0.047101204650810385\n",
      "Gradients [-0.0002896   0.00031526  0.00048777 -0.00078669 -0.00010061], [-6.12998274e-05]\n",
      "Weights [[-0.06009991  0.15773353  0.01611755  0.53941257  0.00379695]], [-0.50030619]\n",
      "Iteration 280000 cost = 0.04710012170693835\n",
      "Gradients [-0.00028391  0.00030883  0.00047602 -0.00076622 -0.00010055], [-5.54083257e-05]\n",
      "Weights [[-0.05981316  0.15742149  0.01563568  0.54018898  0.00389753]], [-0.50024786]\n",
      "Iteration 290000 cost = 0.047099091065004234\n",
      "x [[0.11623617 0.11623617 0.11623617 0.11623617 0.11623617]\n",
      " [0.09388506 0.09388506 0.09388506 0.09388506 0.09388506]\n",
      " [0.09387204 0.09387204 0.09387204 0.09387204 0.09387204]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = np.zeros((3, 5))\n",
    "W = np.zeros((1, 5))\n",
    "model = Linear(W, 0.0)\n",
    "trainer = Trainer(model, lr=0.0001, n_iters=300_000, t_iter=10_000)\n",
    "y = np.expand_dims(y, axis=1) if len(y.shape) < 2 else y\n",
    "for i in range(3):\n",
    "    print()\n",
    "    print(f\"{i} ********************************** \")\n",
    "    print()\n",
    "    x[i] = trainer.fit(X, y)[1]\n",
    "    print('x',x)\n",
    "# print(x[0])\n",
    "# print('X: ', X.shape)\n",
    "# print('y: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.59949287, 0.42275295, 0.42908534],\n",
       "        [0.8900833 , 0.6574656 , 0.66376544],\n",
       "        [1.08768479, 0.81707021, 0.8233479 ],\n",
       "        [1.68048925, 1.29588401, 1.30209531],\n",
       "        [1.80834904, 1.39915758, 1.40535455],\n",
       "        [0.75059989, 0.54480353, 0.55111899],\n",
       "        [0.68085819, 0.4884725 , 0.49479576],\n",
       "        [0.75059989, 0.54480353, 0.55111899],\n",
       "        [1.22716819, 0.92973228, 0.93599435],\n",
       "        [1.35502798, 1.03300584, 1.0392536 ],\n",
       "        [0.68085819, 0.4884725 , 0.49479576],\n",
       "        [0.79709436, 0.58235756, 0.5886678 ],\n",
       "        [1.29690989, 0.98606331, 0.99231758],\n",
       "        [0.80871798, 0.59174606, 0.59805501],\n",
       "        [1.83159628, 1.41793459, 1.42412896],\n",
       "        [0.91333053, 0.67624262, 0.68253984],\n",
       "        [1.90133798, 1.47426563, 1.48045218],\n",
       "        [1.37827521, 1.05178286, 1.058028  ],\n",
       "        [0.83196521, 0.61052307, 0.61682942],\n",
       "        [1.37827521, 1.05178286, 1.058028  ],\n",
       "        [0.86683606, 0.63868859, 0.64499103],\n",
       "        [1.79672542, 1.38976907, 1.39596735],\n",
       "        [0.80871798, 0.59174606, 0.59805501],\n",
       "        [0.69248181, 0.497861  , 0.50418297],\n",
       "        [1.68048925, 1.29588401, 1.30209531],\n",
       "        [0.71572904, 0.51663801, 0.52295738],\n",
       "        [1.62237117, 1.24894148, 1.25515929],\n",
       "        [1.18067372, 0.89217825, 0.89844554],\n",
       "        [1.14580287, 0.86401274, 0.87028392],\n",
       "        [1.05281394, 0.78890469, 0.79518629],\n",
       "        [1.56425308, 1.20199895, 1.20822327],\n",
       "        [1.56425308, 1.20199895, 1.20822327],\n",
       "        [1.33178074, 1.01422883, 1.02047919],\n",
       "        [1.47126415, 1.1268909 , 1.13312564],\n",
       "        [0.70410543, 0.50724951, 0.51357017],\n",
       "        [1.0295667 , 0.77012768, 0.77641188],\n",
       "        [1.63399479, 1.25832999, 1.26454649],\n",
       "        [1.36665159, 1.04239435, 1.0486408 ],\n",
       "        [0.75059989, 0.54480353, 0.55111899],\n",
       "        [1.35502798, 1.03300584, 1.0392536 ],\n",
       "        [1.19229734, 0.90156676, 0.90783274],\n",
       "        [1.38989883, 1.06117136, 1.06741521],\n",
       "        [1.22716819, 0.92973228, 0.93599435],\n",
       "        [0.78547075, 0.57296905, 0.5792806 ],\n",
       "        [0.80871798, 0.59174606, 0.59805501],\n",
       "        [0.68085819, 0.4884725 , 0.49479576],\n",
       "        [1.49451138, 1.14566792, 1.15190004],\n",
       "        [1.14580287, 0.86401274, 0.87028392],\n",
       "        [1.93620883, 1.50243114, 1.5086138 ],\n",
       "        [0.65761096, 0.46969548, 0.47602136]]),\n",
       " array([0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2,\n",
       "        0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 2, 1, 2, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www = np.array([[0.11623617, 0.11623617, 0.11623617, 0.11623617, 0.11623617],\n",
    "               [0.09388506, 0.09388506, 0.09388506, 0.09388506, 0.09388506],\n",
    "               [0.09387204, 0.09387204, 0.09387204, 0.09387204, 0.09387204]])\n",
    "wb = np.array([-0.55124521, -0.50670914, -0.50024786])\n",
    "result = X_test @ www.T + wb\n",
    "result, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.46\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for i in range(len(result)):\n",
    "    if round(sum(result[i])/len(result[i])) == y_test[i]:\n",
    "        t+=1\n",
    "print('accuracy is:', t/len(result))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
